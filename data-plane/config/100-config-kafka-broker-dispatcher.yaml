apiVersion: v1
kind: ConfigMap
metadata:
  name: config-kafka-broker-dispatcher
  namespace: knative-eventing
data:
  config-kafka-broker-producer.properties: |
    bootstrap.servers=my-cluster-kafka-bootstrap.kafka:9092
    # key.serializer=org.apache.kafka.common.serialization.StringSerializer
    # value.serializer=org.apache.kafka.common.serialization.StringSerializer
    acks=1
    buffer.memory=33554432
    compression.type=snappy
    retries=2147483647
    batch.size=16384
    client.dns.lookup=use_all_dns_ips
    client.id=KKBD # Knative Kafka Broker Dispatcher
    connections.max.idle.ms=600000
    delivery.timeout.ms=120000
    linger.ms=0
    max.block.ms=60000
    max.request.size=1048576
    partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner
    receive.buffer.bytes=-1
    request.timeout.ms=30000
    enable.idempotence=false
    # interceptor.classes=""
    max.in.flight.requests.per.connection=5
    metadata.max.age.ms=300000
    # metric.reporters=""
    metrics.num.samples=2
    metrics.recording.level=INFO
    metrics.sample.window.ms=30000
    reconnect.backoff.max.ms=1000
    reconnect.backoff.ms=50
    retry.backoff.ms=100
    # transaction.timeout.ms=60000
    # transactional.id=null
  config-kafka-broker-consumer.properties: |
    bootstrap.servers=my-cluster-kafka-bootstrap.kafka:9092
    # key.serializer=org.apache.kafka.common.serialization.StringSerializer
    # value.serializer=org.apache.kafka.common.serialization.StringSerializer
    fetch.min.bytes=1
    # group.id= dynamically set
    heartbeat.interval.ms=3000
    max.partition.fetch.bytes=1048576
    session.timeout.ms=10000
    # ssl.key.password=
    # ssl.keystore.location=
    # ssl.keystore.password=
    # ssl.truststore.location=
    # ssl.truststore.password=
    allow.auto.create.topics=true
    auto.offsets.reset=latest
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=540000
    default.api.timeout.ms=60000
    enable.auto.commit=false
    exclude.internals.topics=false
    fetch.max.bytes=52428800
    # group.instance.id=
    isolation.level=read_uncommitted
    max.poll.interval.ms=300000
    max.poll.records=500
    partition.assignement.strategy=org.apache.kafka.clients.consumer.CooperativeStickyAssignor # Kafka 2.3 required
    receive.buffer.bytes=65536
    request.timeout.ms=30000
    # sasl.client.callback.handler.class=
    # sasl.jaas.config=
    # sasl.kerberos.service.name=
    # sasl.login.callback.handler.class
    # sasl.login.class
    # sasl.mechanism
    security.protocol=PLAINTEXT
    send.buffer.bytes=131072
    # ssl.enabled.protocols=
    # ssl.keystore.type=
    # ssl.protocol=
    # ssl.provider=
    auto.commit.interval.ms=5000
    check.crcs=true
    client.id=KKBD # Knative Kafka Broker Dispatcher
    # client.rack=
    fetch.max.wait.ms=500
    # interceptor.classes=
    metadata.max.age.ms=600000
    # metrics.reporters=
    # metrics.num.samples=
    # metrics.recording.level=INFO
    # metrics.sample.window.ms=
    reconnect.backoff.max.ms=1000
    retry.backoff.ms=100
    # sasl.kerberos.kinit.cmd=
    # sasl.kerberos.min.time.before.relogin=
    # sasl.kerberos.ticket.renew.jitter=
    # sasl.login.refresh.buffer.seconds=
    # sasl.login.refresh.min.period.seconds=
    # sasl.login.refresh.window.factor
    # sasl.login.refresh.window.jitter
    # security.providers
    # ssl.cipher.suites
    # ssl.endpoint.identification.algorithm
    # ssl.keymanager.algorithm
    # ssl.secure.random.implementation
    # ssl.trustmanager.algorithm


