---

# Copyright 2020 The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: v1
kind: ConfigMap
metadata:
  name: config-kafka-broker-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: devel
data:
  config-kafka-broker-producer.properties: |
    key.serializer=org.apache.kafka.common.serialization.StringSerializer
    value.serializer=io.cloudevents.kafka.CloudEventSerializer
    acks=all
    buffer.memory=33554432
    # compression.type=snappy
    retries=100
    batch.size=16384
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=600000
    delivery.timeout.ms=120000
    linger.ms=0
    max.block.ms=60000
    max.request.size=1048576
    partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner
    receive.buffer.bytes=-1
    request.timeout.ms=30000
    enable.idempotence=false
    max.in.flight.requests.per.connection=5
    metadata.max.age.ms=300000
    # metric.reporters=""
    metrics.num.samples=2
    metrics.recording.level=INFO
    metrics.sample.window.ms=30000
    reconnect.backoff.max.ms=1000
    reconnect.backoff.ms=50
    retry.backoff.ms=100
    # transaction.timeout.ms=60000
    # transactional.id=null
  config-kafka-broker-consumer.properties: |
    key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
    value.deserializer=io.cloudevents.kafka.CloudEventDeserializer
    fetch.min.bytes=1
    heartbeat.interval.ms=3000
    max.partition.fetch.bytes=1048576
    session.timeout.ms=10000
    # ssl.key.password=
    # ssl.keystore.location=
    # ssl.keystore.password=
    # ssl.truststore.location=
    # ssl.truststore.password=
    allow.auto.create.topics=false
    auto.offset.reset=earliest
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=540000
    default.api.timeout.ms=60000
    enable.auto.commit=false
    exclude.internal.topics=true
    fetch.max.bytes=5428800
    isolation.level=read_uncommitted
    max.poll.interval.ms=300000
    max.poll.records=500
    # partition.assignment.strategy=org.apache.kafka.clients.consumer.CooperativeStickyAssignor
    receive.buffer.bytes=65536
    request.timeout.ms=30000
    # sasl.client.callback.handler.class=
    # sasl.jaas.config=
    # sasl.kerberos.service.name=
    # sasl.login.callback.handler.class
    # sasl.login.class
    # sasl.mechanism
    security.protocol=PLAINTEXT
    send.buffer.bytes=131072
    # ssl.enabled.protocols=
    # ssl.keystore.type=
    # ssl.protocol=
    # ssl.provider=
    auto.commit.interval.ms=5000
    check.crcs=true
    # client.rack=
    fetch.max.wait.ms=500
    # interceptor.classes=
    metadata.max.age.ms=600000
    # metrics.reporters=
    # metrics.num.samples=
    # metrics.recording.level=INFO
    # metrics.sample.window.ms=
    reconnect.backoff.max.ms=1000
    retry.backoff.ms=100
    # sasl.kerberos.kinit.cmd=
    # sasl.kerberos.min.time.before.relogin=
    # sasl.kerberos.ticket.renew.jitter=
    # sasl.login.refresh.buffer.seconds=
    # sasl.login.refresh.min.period.seconds=
    # sasl.login.refresh.window.factor
    # sasl.login.refresh.window.jitter
    # security.providers
    # ssl.cipher.suites
    # ssl.endpoint.identification.algorithm
    # ssl.keymanager.algorithm
    # ssl.secure.random.implementation
    # ssl.trustmanager.algorithm
  config-kafka-broker-webclient.properties: |
    idleTimeout=10000
  config-kafka-broker-httpserver.properties: |
    idleTimeout=10000
