syntax = 'proto3';

option go_package = "control-plane/pkg/contract";
option java_package = "dev.knative.eventing.kafka.broker.contract";
option java_outer_classname = "DataPlaneContract";

// We don't use the google.protobuf.Empty type because
// configuring the include directory is a mess for the contributors and for the build scripts.
// Hence, more than dealing with contributors that can't get their dev environment
// working with the project, we prefer to have this additional single line of code.
// Protobuf include nightmare? No thanks!
message Empty {}

message Exact {
  map<string, string> attributes = 1;
}

message Prefix {
  map<string, string> attributes = 1;
}

message Suffix {
  map<string, string> attributes = 1;
}

message All {
  repeated DialectedFilter filters = 1;
}

message Any {
  repeated DialectedFilter filters = 1;
}

message Not {
  DialectedFilter filter = 1;
}

message CESQL {
  string expression = 1;
}

message DialectedFilter {
  oneof filter {
    Exact exact = 1;
    Prefix prefix = 2;
    Suffix suffix = 3;
    All all = 4;
    Any any = 5;
    Not not = 6;
    CESQL cesql = 7;
  }
}

message Filter {
  // attributes filters events by exact match on event context attributes.
  // Each key in the map is compared with the equivalent key in the event
  // context. An event passes the filter if all values are equal to the
  // specified values.
  //
  // Nested context attributes are not supported as keys. Only string values are supported.
  map<string, string> attributes = 1;
}

// BackoffPolicyType is the type for backoff policies
enum BackoffPolicy {

  // Exponential backoff policy
  Exponential = 0;

  // Linear backoff policy
  Linear = 1;
}

message EgressConfig {
  // Dead letter is where the event is sent when something goes wrong
  string deadLetter = 1;

  // retry is the minimum number of retries the sender should attempt when
  // sending an event before moving it to the dead letter sink.
  //
  // Setting retry to 0 means don't retry.
  uint32 retry = 2;

  // backoffPolicy is the retry backoff policy (linear, exponential).
  BackoffPolicy backoffPolicy = 3;

  // backoffDelay is the delay before retrying in milliseconds.
  uint64 backoffDelay = 4;

  // timeout is the single request timeout (not the overall retry timeout)
  uint64 timeout = 5;
}

// Check dev.knative.eventing.kafka.broker.dispatcher.consumer.DeliveryOrder for more details
enum DeliveryOrder {
  UNORDERED = 0;
  ORDERED = 1;
}

enum KeyType {
  String = 0;
  Integer = 1;
  Double = 2;
  ByteArray = 3;
}

message Egress {
  // consumer group name
  string consumerGroup = 1;

  // destination is the sink where events are sent.
  string destination = 2;

  oneof replyStrategy {
    // Send the response to an url
    string replyUrl = 3;

    // Send the response to a Kafka topic
    Empty replyToOriginalTopic = 4;

    // Discard response.
    Empty discardReply = 9;
  }
  // A filter for performing exact match against Cloud Events attributes
  Filter filter = 5;

  // Id of the egress
  // It's the same as the Kubernetes resource uid
  string uid = 6;

  // Egress configuration.
  // It overrides Resource's EgressConfig.
  EgressConfig egressConfig = 7;

  // Delivery guarantee to use
  // Empty defaults to unordered
  DeliveryOrder deliveryOrder = 8;

  // Kafka record key type.
  KeyType keyType = 10;

  // Resource reference.
  //
  // This reference is used to reference the associated resource for data plane
  // activities such as:
  // - tagging metrics
  Reference reference = 11;

  // CNCF CloudEvents SubscriptionsAPI compliant filters
  repeated DialectedFilter dialectedFilter = 12;

  // Number of virtual replicas.
  int32 vReplicas = 13;
}

// CloudEvent content mode
enum ContentMode {
  BINARY = 0;
  STRUCTURED = 1;
}

// Ingress is the definition for HTTP ingress that is receiving the events
// into the Knative Kafka component.
//
// path and host fields are used for identifying the targets. They are exclusive.
// When a request comes with "/some-path", hostname will not be checked.
// When a request comes with "/", only hostname matching will be done.
// It is allowed to specify both path and host in ingress contract
// to support both modes.
message Ingress {
  // Optional content mode to use when pushing messages to Kafka
  ContentMode contentMode = 1;

  // path to listen for incoming events.
  string path = 2;

  // host header to match
  string host = 3;
}

// Kubernetes resource reference.
message Reference {

  // Object id.
  string uuid = 1;

  // Object namespace.
  string namespace = 2;

  // Object name.
  string name = 3;

  // Object version.
  string version = 4;
}

enum SecretField {
  SASL_MECHANISM = 0;
  CA_CRT = 1;
  USER_CRT = 2;
  USER_KEY = 3;
  USER = 4;
  PASSWORD = 5;
}

message SecretReference {
  // Secret reference.
  Reference reference = 1;

  // Multiple key-field references.
  repeated KeyFieldReference keyFieldReferences = 2;
}

message KeyFieldReference {
  // Key in the secret.
  string secretKey = 2;

  // Field name.
  SecretField field = 3;
}

enum Protocol {
  PLAINTEXT = 0;
  SASL_PLAINTEXT = 1;
  SSL = 2;
  SASL_SSL = 3;
}

message MultiSecretReference {

  // Protocol.
  Protocol protocol = 1;

  // Secret references.
  repeated SecretReference references = 2;
}

// CloudEvent overrides.
message CloudEventOverrides {
  map<string, string> extensions = 1;
}

message Resource {
  // Id of the resource
  // It's the same as the Kubernetes resource uid
  string uid = 1;

  // Topics name
  // Note: If there is an ingress configured, then this field must have exactly 1 element otherwise,
  //  if the resource does just dispatch from Kafka, then this topic list can contain multiple elements
  repeated string topics = 2;

  // A comma separated list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
  // Note: we're using a comma separated list simply because that's how java kafka client likes it.
  string bootstrapServers = 3;

  // Optional ingress for this topic
  Ingress ingress = 4;

  // Optional configuration of egress valid for the whole resource
  EgressConfig egressConfig = 5;

  // Optional egresses for this topic
  repeated Egress egresses = 6;

  oneof Auth {
    // No auth configured.
    Empty absentAuth = 7;

    // Secret reference.
    //
    // Secret format:
    //
    //   protocol: (PLAINTEXT | SASL_PLAINTEXT | SSL | SASL_SSL)
    //   sasl.mechanism: (SCRAM-SHA-256 | SCRAM-SHA-512)
    //   ca.crt: <CA PEM certificate>
    //   user.crt: <User PEM certificate>
    //   user.key: <User PEM key>
    //   user: <SASL username>
    //   password: <SASL password>
    //
    // Validation:
    //   - protocol=PLAINTEXT
    //   - protocol=SSL
    //     - required:
    //       - ca.crt
    //       - user.crt
    //       - user.key
    //   - protocol=SASL_PLAINTEXT
    //     - required:
    //       - sasl.mechanism
    //       - user
    //       - password
    //   - protocol=SASL_SSL
    //     - required:
    //       - sasl.mechanism
    //       - ca.crt
    //       - user.crt
    //       - user.key
    //       - user
    //       - password
    Reference authSecret = 8;

    // Multiple secrets reference.
    MultiSecretReference multiAuthSecret = 9;
  }

  CloudEventOverrides cloudEventOverrides = 10;

  // Resource reference.
  //
  // This reference is used to reference the associated resource for data plane
  // activities such as:
  // - setting the `source` attribute of a KafkaSource event (when it's not a CloudEvent)
  // - tagging metrics
  Reference reference = 11;
}

message Contract {
  // Count each contract update.
  // Make sure each data plane pod has the same contract generation number.
  uint64 generation = 1;

  repeated Resource resources = 2;
}
